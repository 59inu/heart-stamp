import fs from 'fs';
import path from 'path';
import { exec } from 'child_process';
import { promisify } from 'util';
import archiver from 'archiver';
import { S3Service } from './s3Service';

const execAsync = promisify(exec);

const BACKUP_DIR = path.join(__dirname, '../../backups');
const UPLOADS_DIR = path.join(__dirname, '../../uploads');
const RETENTION_DAYS = 7; // 7ì¼ì¹˜ ë°±ì—… ë³´ê´€

export class BackupService {
  /**
   * ë°±ì—… ë””ë ‰í† ë¦¬ ì´ˆê¸°í™”
   */
  private static ensureBackupDir(): void {
    if (!fs.existsSync(BACKUP_DIR)) {
      fs.mkdirSync(BACKUP_DIR, { recursive: true });
      console.log('âœ… [Backup] Created backup directory');
    }
  }

  /**
   * PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (pg_dump ì‚¬ìš©)
   */
  private static async performDatabaseBackup(timestamp: string): Promise<{ path: string; size: number }> {
    try {
      const backupPath = path.join(BACKUP_DIR, `${timestamp}_diary_backup.sql`);

      console.log('ğŸ“¦ [Backup] Starting database backup...');

      // pg_dumpë¥¼ ì‚¬ìš©í•˜ì—¬ SQL ë°±ì—… ìƒì„±
      const databaseUrl = process.env.DATABASE_URL;
      if (!databaseUrl) {
        throw new Error('DATABASE_URL not configured');
      }

      await execAsync(`pg_dump "${databaseUrl}" > "${backupPath}"`);

      const stats = fs.statSync(backupPath);
      const sizeMB = (stats.size / 1024 / 1024).toFixed(2);

      console.log(`âœ… [Backup] Database backup created: ${sizeMB}MB`);

      return { path: backupPath, size: stats.size };
    } catch (error) {
      console.error('âŒ [Backup] Database backup failed:', error);
      throw error;
    }
  }

  /**
   * uploads í´ë” ë°±ì—… (ZIP ì••ì¶•)
   */
  private static async performUploadsBackup(timestamp: string): Promise<{ path: string; size: number }> {
    return new Promise((resolve, reject) => {
      try {
        const backupPath = path.join(BACKUP_DIR, `${timestamp}_uploads.zip`);

        // uploads í´ë”ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if (!fs.existsSync(UPLOADS_DIR)) {
          console.log('âš ï¸  [Backup] No uploads directory found, skipping...');
          return resolve({ path: '', size: 0 });
        }

        // uploads í´ë”ê°€ ë¹„ì–´ìˆìœ¼ë©´ ìŠ¤í‚µ
        const files = fs.readdirSync(UPLOADS_DIR);
        if (files.length === 0) {
          console.log('âš ï¸  [Backup] Uploads directory is empty, skipping...');
          return resolve({ path: '', size: 0 });
        }

        console.log('ğŸ“¦ [Backup] Starting uploads backup...');

        const output = fs.createWriteStream(backupPath);
        const archive = archiver('zip', { zlib: { level: 9 } }); // ìµœëŒ€ ì••ì¶•

        output.on('close', () => {
          const stats = fs.statSync(backupPath);
          const sizeMB = (stats.size / 1024 / 1024).toFixed(2);
          console.log(`âœ… [Backup] Uploads backup created: ${sizeMB}MB`);
          resolve({ path: backupPath, size: stats.size });
        });

        archive.on('error', (err) => {
          console.error('âŒ [Backup] Uploads backup failed:', err);
          reject(err);
        });

        archive.pipe(output);
        archive.directory(UPLOADS_DIR, false); // uploads/ í´ë” ë‚´ìš© ì••ì¶•
        archive.finalize();
      } catch (error) {
        console.error('âŒ [Backup] Uploads backup failed:', error);
        reject(error);
      }
    });
  }

  /**
   * ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì‚­ì œ (RETENTION_DAYSë³´ë‹¤ ì˜¤ë˜ëœ íŒŒì¼)
   */
  private static cleanOldBackups(): void {
    try {
      if (!fs.existsSync(BACKUP_DIR)) return;

      const now = Date.now();
      const cutoffTime = now - RETENTION_DAYS * 24 * 60 * 60 * 1000;
      const files = fs.readdirSync(BACKUP_DIR);

      let deletedCount = 0;

      files.forEach((file) => {
        const filePath = path.join(BACKUP_DIR, file);
        const stats = fs.statSync(filePath);

        // JSON ë©”íƒ€ë°ì´í„° íŒŒì¼ê³¼ ë°±ì—… íŒŒì¼ ëª¨ë‘ ì‚­ì œ
        if (stats.mtimeMs < cutoffTime) {
          fs.unlinkSync(filePath);
          deletedCount++;
        }
      });

      if (deletedCount > 0) {
        console.log(`ğŸ—‘ï¸  [Backup] Deleted ${deletedCount} old backup file(s)`);
      }
    } catch (error) {
      console.error('âŒ [Backup] Failed to clean old backups:', error);
    }
  }

  /**
   * ë°±ì—… ë©”íƒ€ë°ì´í„° ì €ì¥
   */
  private static saveBackupMetadata(
    timestamp: string,
    dbSize: number,
    uploadsSize: number,
    success: boolean,
    duration: number,
    error?: string
  ): void {
    try {
      const metadata = {
        timestamp,
        db_size_bytes: dbSize,
        db_size_mb: (dbSize / 1024 / 1024).toFixed(2),
        uploads_size_bytes: uploadsSize,
        uploads_size_mb: (uploadsSize / 1024 / 1024).toFixed(2),
        total_size_mb: ((dbSize + uploadsSize) / 1024 / 1024).toFixed(2),
        success,
        duration_seconds: duration.toFixed(2),
        error: error || null,
      };

      const metadataPath = path.join(BACKUP_DIR, `${timestamp}_metadata.json`);
      fs.writeFileSync(metadataPath, JSON.stringify(metadata, null, 2));
    } catch (error) {
      console.error('âŒ [Backup] Failed to save metadata:', error);
    }
  }

  /**
   * S3ì— ë°±ì—… íŒŒì¼ ì—…ë¡œë“œ
   */
  private static async uploadToS3(filePath: string, filename: string): Promise<void> {
    if (!S3Service.isConfigured()) {
      console.log('âš ï¸  [Backup] S3 not configured, skipping S3 upload');
      return;
    }

    try {
      const s3Key = `backups/${filename}`;
      await S3Service.uploadBackupFile(filePath, s3Key);
    } catch (error) {
      console.error(`âŒ [Backup] Failed to upload ${filename} to S3:`, error);
      // S3 ì—…ë¡œë“œ ì‹¤íŒ¨í•´ë„ ë¡œì»¬ ë°±ì—…ì€ ìœ ì§€ë˜ë¯€ë¡œ ì—ëŸ¬ ë˜ì§€ì§€ ì•ŠìŒ
    }
  }

  /**
   * ì „ì²´ ë°±ì—… ìˆ˜í–‰ (ë©”ì¸ í•¨ìˆ˜)
   */
  static async performFullBackup(): Promise<void> {
    const startTime = Date.now();
    const timestamp = new Date().toISOString().split('T')[0]; // 2025-11-03

    console.log(`\nğŸ”„ [Backup] Starting daily backup at ${new Date().toISOString()}`);

    try {
      // ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
      this.ensureBackupDir();

      // ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
      const dbBackup = await this.performDatabaseBackup(timestamp);

      // ì´ë¯¸ì§€ í´ë” ë°±ì—…
      const uploadsBackup = await this.performUploadsBackup(timestamp);

      // S3ì— ë°±ì—… ì—…ë¡œë“œ
      if (S3Service.isConfigured()) {
        console.log('ğŸ“¤ [Backup] Uploading backups to S3...');

        // DB ë°±ì—… ì—…ë¡œë“œ
        if (dbBackup.path) {
          await this.uploadToS3(dbBackup.path, path.basename(dbBackup.path));
        }

        // uploads ë°±ì—… ì—…ë¡œë“œ
        if (uploadsBackup.path) {
          await this.uploadToS3(uploadsBackup.path, path.basename(uploadsBackup.path));
        }

        // ë©”íƒ€ë°ì´í„° ì—…ë¡œë“œ
        const metadataPath = path.join(BACKUP_DIR, `${timestamp}_metadata.json`);
        if (fs.existsSync(metadataPath)) {
          await this.uploadToS3(metadataPath, `${timestamp}_metadata.json`);
        }

        // S3 ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
        await S3Service.cleanOldBackups('backups/', RETENTION_DAYS);
      }

      // ë¡œì»¬ ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
      this.cleanOldBackups();

      const duration = (Date.now() - startTime) / 1000;

      // ë©”íƒ€ë°ì´í„° ì €ì¥
      this.saveBackupMetadata(
        timestamp,
        dbBackup.size,
        uploadsBackup.size,
        true,
        duration
      );

      console.log(`âœ… [Backup] Daily backup completed successfully in ${duration.toFixed(2)}s\n`);
    } catch (error) {
      const duration = (Date.now() - startTime) / 1000;
      const errorMessage = error instanceof Error ? error.message : 'Unknown error';

      // ì‹¤íŒ¨ ë©”íƒ€ë°ì´í„° ì €ì¥
      this.saveBackupMetadata(timestamp, 0, 0, false, duration, errorMessage);

      console.error(`âŒ [Backup] Daily backup failed after ${duration.toFixed(2)}s:`, error);
      throw error;
    }
  }

  /**
   * ë°±ì—… ëª©ë¡ ì¡°íšŒ (ê´€ë¦¬ìš©)
   */
  static listBackups(): Array<{ date: string; files: string[]; metadata?: any }> {
    try {
      if (!fs.existsSync(BACKUP_DIR)) {
        return [];
      }

      const files = fs.readdirSync(BACKUP_DIR);
      const backupsByDate: Record<string, string[]> = {};

      // ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
      files.forEach((file) => {
        const match = file.match(/^(\d{4}-\d{2}-\d{2})_/);
        if (match) {
          const date = match[1];
          if (!backupsByDate[date]) {
            backupsByDate[date] = [];
          }
          backupsByDate[date].push(file);
        }
      });

      // ë°°ì—´ë¡œ ë³€í™˜ ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€
      return Object.entries(backupsByDate)
        .map(([date, fileList]) => {
          const metadataFile = fileList.find((f) => f.endsWith('_metadata.json'));
          let metadata = null;

          if (metadataFile) {
            const metadataPath = path.join(BACKUP_DIR, metadataFile);
            metadata = JSON.parse(fs.readFileSync(metadataPath, 'utf-8'));
          }

          return { date, files: fileList, metadata };
        })
        .sort((a, b) => b.date.localeCompare(a.date)); // ìµœì‹ ìˆœ ì •ë ¬
    } catch (error) {
      console.error('âŒ [Backup] Failed to list backups:', error);
      return [];
    }
  }
}
